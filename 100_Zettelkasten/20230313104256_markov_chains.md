
---
creation date: 2023-03-13 10:42
last updated: 2023-03-13 10:42
---
# [[20230313104256_markov_chains]] - Markov chains

__Tags__: #markov-chains 

---
__Contents__: A Markov chain is a discrete stochastic process, note $\{X_n\}_{n \in \mathbb{N}}$ this process. As a discrete process, it can be in multiple states, note $\{1, \dots, I\}$ these states. We are interested by modeling the probability $p_{ij}$ to go from state $i$ to state $j$.

A Markov chain relies on one property, called the _Markovian property_: The conditional distribution of any future state given past and present states is independent of the past states.

Different types of Markov chain exists:
* Homogeneous Markov chains 

__References__:

